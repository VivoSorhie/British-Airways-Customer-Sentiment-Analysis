{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMhd5JVr6ssmS+M1RmxpXqI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VivoSorhie/British-Airways-Customer-Sentiment-Analysis/blob/main/British_Airways_Reviews_Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# British Airways Review: Sentiment Analysis\n",
        "\n",
        "## 1. Setup and Library Imports\n",
        "\n",
        "Our first step is to establish a robust environment. We will import the essential Python libraries that form the foundation of our analysis.\n",
        "\n",
        "* **Pandas**: For loading, manipulating, and cleaning our dataset.\n",
        "* **Seaborn & Matplotlib**: For creating clear and insightful data visualizations.\n",
        "* **Google Colab Files**: A specific utility to handle file uploads within the Colab environment.\n",
        "\n",
        "Executing this ensures all the tools we need are ready before we handle any data."
      ],
      "metadata": {
        "id": "4kPABbwOPJ3y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IyCzaxIxO13q"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "import io\n",
        "\n",
        "# Set a consistent style for all our plots\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (12, 7)\n",
        "\n",
        "print(\"Libraries imported successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "omrhIFYmPQZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Data Loading and Initial Inspection\n",
        "\n",
        "The file has been uploaded to the Colab environment. We will now load it into a pandas DataFrame, which is the standard data structure for data analysis in Python.\n",
        "\n",
        "Immediately after loading, we must perform two critical verification steps:\n",
        "1.  **`.head()`**: Inspect the first five rows to ensure the data has been parsed correctly and matches our expectations of the columns and content.\n",
        "2.  **`.info()`**: Programmatically check the data types of each column and look for any null (missing) values. This provides a concise, technical summary of the dataset's structure.\n",
        "\n",
        "This disciplined approach ensures data integrity from the very beginning."
      ],
      "metadata": {
        "id": "UTyLsWC_R4zM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The 'uploaded' variable now holds your file. Let's load it into a DataFrame.\n",
        "# This code assumes the uploaded file is a CSV.\n",
        "try:\n",
        "    # Get the filename from the uploaded dictionary\n",
        "    file_name = list(uploaded.keys())[0]\n",
        "\n",
        "    # Read the CSV file into a pandas DataFrame\n",
        "    df = pd.read_csv(io.BytesIO(uploaded[file_name]))\n",
        "\n",
        "    print(f\"Successfully loaded '{file_name}' into DataFrame.\")\n",
        "\n",
        "    print(\"\\n--- First 5 Rows ---\")\n",
        "    display(df.head())\n",
        "\n",
        "    print(\"\\n--- DataFrame Info ---\")\n",
        "    df.info()\n",
        "\n",
        "except IndexError:\n",
        "    print(\"Error: No file was uploaded. Please run the upload cell again.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")\n",
        "    print(\"Please ensure the uploaded file is a valid CSV.\")"
      ],
      "metadata": {
        "id": "b0RewqSLQ2hT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Data Cleaning and Preparation\n",
        "\n",
        "Before any analysis can begin, we must ensure the data is clean and fit for purpose. Based on the initial inspection, we will perform the following non-negotiable cleaning steps:\n",
        "\n",
        "1.  **Drop Irrelevant Columns**: The `Unnamed: 0` column provides no analytical value and will be removed.\n",
        "2.  **Handle Missing Ratings**: The `OverallRating` is critical for creating our sentiment labels. Rows with missing ratings (5 in this case) will be dropped to ensure the integrity of our training data.\n",
        "3.  **Select Core Features**: To streamline our analysis, we will create a new DataFrame that contains only the two columns essential for this project: `OverallRating` and `ReviewBody`.\n",
        "4.  **Rename Columns**: We will rename the columns to `rating` and `review` for simplicity and clarity.\n",
        "5.  **Verify Data Types**: Ensure the `rating` column is of integer type.\n",
        "\n",
        "This process results in a clean, focused dataset, which is the necessary foundation for reliable analysis."
      ],
      "metadata": {
        "id": "woj3hji6RwlK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Drop the 'Unnamed: 0' column\n",
        "df_cleaned = df.drop('Unnamed: 0', axis=1)\n",
        "\n",
        "# 2. Drop rows where 'OverallRating' is missing\n",
        "df_cleaned.dropna(subset=['OverallRating'], inplace=True)\n",
        "\n",
        "# 3. Select and rename the essential columns\n",
        "df_final = df_cleaned[['OverallRating', 'ReviewBody']].copy()\n",
        "df_final.rename(columns={'OverallRating': 'rating', 'ReviewBody': 'review'}, inplace=True)\n",
        "\n",
        "# 4. Convert 'rating' column to integer\n",
        "df_final['rating'] = df_final['rating'].astype(int)\n",
        "\n",
        "print(\"Data cleaning complete.\")\n",
        "print(\"\\n--- Final DataFrame Info ---\")\n",
        "df_final.info()\n",
        "\n",
        "print(\"\\n--- First 5 Rows of Cleaned Data ---\")\n",
        "display(df_final.head())"
      ],
      "metadata": {
        "id": "H_zJdga-RcJq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Exploratory Data Analysis (EDA): Rating Distribution\n",
        "\n",
        "With a clean dataset, our first analytical action is to visualize the distribution of the `rating` column. A count plot is the most effective tool for this purpose, as it provides an unambiguous representation of the frequency of each rating score.\n",
        "\n",
        "This visualization will allow us to:\n",
        "1.  Objectively assess the overall sentiment tendency of the reviews.\n",
        "2.  Identify any skewness, for instance, a disproportionately high number of very low or very high ratings.\n",
        "3.  Make an informed decision on how to map these numerical ratings to sentiment categories in the next step.\n",
        "\n",
        "Analyzing this distribution is a foundational step for understanding the dataset's characteristics."
      ],
      "metadata": {
        "id": "VuPA1nGYSi-j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a count plot to visualize the distribution of ratings\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.countplot(x='rating', data=df_final, palette='viridis', order=range(1, 11))\n",
        "\n",
        "# Set clear and informative labels\n",
        "plt.title('Distribution of Customer Ratings', fontsize=16)\n",
        "plt.xlabel('Rating (1-10)', fontsize=12)\n",
        "plt.ylabel('Number of Reviews', fontsize=12)\n",
        "plt.xticks(range(0, 10), labels=range(1, 11)) # Ensure all integer labels are shown\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HQsKYayISE7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4a. Analysis of Detailed Service Ratings\n",
        "\n",
        "To understand the 'why' behind the overall ratings, we must dissect the individual service components. We will analyze the ratings for `SeatComfort`, `CabinStaffService`, `GroundService`, and `ValueForMoney`.\n",
        "\n",
        "Our objective is twofold:\n",
        "1.  **Quantitative Summary**: Calculate the mean score for each component to get a quick, numerical comparison of performance.\n",
        "2.  **Distribution Visualization**: Use box plots to visualize the distribution, median, and variance of ratings for each component. This is superior to a simple bar chart as it reveals the spread and potential outliers in the data.\n",
        "\n",
        "This analysis will provide a granular view of British Airways' operational strengths and weaknesses as perceived by its customers. We will use our `df_cleaned` DataFrame for this, as it contains these columns."
      ],
      "metadata": {
        "id": "EXjW7aRpYF06"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select the detailed rating columns for analysis\n",
        "service_ratings_cols = ['SeatComfort', 'CabinStaffService', 'GroundService', 'ValueForMoney']\n",
        "\n",
        "# 1. Quantitative Summary: Calculate and print the mean for each\n",
        "print(\"--- Mean Score for Each Service Component ---\")\n",
        "# We use .dropna() here to calculate the mean only on the available data for each column\n",
        "mean_scores = df_cleaned[service_ratings_cols].mean().sort_values()\n",
        "print(mean_scores)\n",
        "\n",
        "# 2. Distribution Visualization: Create box plots\n",
        "plt.figure(figsize=(12, 8))\n",
        "# We need to melt the dataframe to plot multiple columns with seaborn\n",
        "df_melted = df_cleaned[service_ratings_cols].melt(var_name='Service Component', value_name='Rating')\n",
        "\n",
        "sns.boxplot(x='Service Component', y='Rating', data=df_melted, palette='coolwarm')\n",
        "plt.title('Distribution of Detailed Service Ratings', fontsize=16)\n",
        "plt.xlabel('Service Component', fontsize=12)\n",
        "plt.ylabel('Rating (1-5)', fontsize=12)\n",
        "plt.xticks(rotation=15)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7KbQajfYSpBH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4b. EDA: Temporal Analysis of Ratings\n",
        "\n",
        "Having identified key service weaknesses, we will now investigate rating trends over time. This analysis will determine if the overall customer satisfaction has a temporal pattern, such as degradation in recent years.\n",
        "\n",
        "Our process will be:\n",
        "1.  **Data Type Conversion**: Convert the `Datetime` column from a generic object to a proper `datetime` format, which is essential for any time-series analysis.\n",
        "2.  **Feature Extraction**: Extract the **year** from the `Datetime` column to serve as our time-based grouping key.\n",
        "3.  **Aggregation**: Group the data by year and calculate the mean `OverallRating` for each year.\n",
        "4.  **Visualization**: Plot the mean rating over time using a line plot to clearly visualize any trends.\n",
        "\n",
        "This will provide a high-level overview of British Airways' performance trajectory over the years covered in the dataset."
      ],
      "metadata": {
        "id": "lqD8w6QTY1wV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The data preparation steps remain the same\n",
        "df_cleaned['datetime'] = pd.to_datetime(df_cleaned['Datetime'], errors='coerce')\n",
        "df_cleaned.dropna(subset=['datetime'], inplace=True)\n",
        "df_cleaned['year'] = df_cleaned['datetime'].dt.year\n",
        "yearly_avg_rating = df_cleaned.groupby('year')['OverallRating'].mean().reset_index()\n",
        "\n",
        "# 4. Plot the results with a filled area\n",
        "plt.figure(figsize=(12, 7))\n",
        "ax = sns.lineplot(x='year', y='OverallRating', data=yearly_avg_rating, marker='o', color='royalblue', linewidth=2.5)\n",
        "\n",
        "# Add the filled region\n",
        "plt.fill_between(x=yearly_avg_rating['year'], y1=yearly_avg_rating['OverallRating'], color='royalblue', alpha=0.2)\n",
        "\n",
        "plt.title('Average Overall Rating Per Year', fontsize=16)\n",
        "plt.xlabel('Year', fontsize=12)\n",
        "plt.ylabel('Average Rating (1-10)', fontsize=12)\n",
        "plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
        "\n",
        "# Ensure the y-axis starts from 0 for better perspective\n",
        "plt.ylim(0, 10)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "In_EEdnIYA8K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Insights from Temporal Analysis\n",
        "\n",
        "The key observations are as follows:\n",
        "\n",
        "* **Peak Performance (2012-2014)**: The airline's customer satisfaction peaked between 2012 and 2014, with average ratings hovering near a high of 6.0.\n",
        "\n",
        "* **Consistent Long-Term Decline**: Following the peak in 2014, the data shows a persistent downward trajectory. Despite a minor recovery between 2017 and 2019, the overarching trend is one of degradation.\n",
        "\n",
        "* **Recent Sharp Deterioration**: The most critical insight is the sharp decline in the most recent years (post-2019). The average rating has fallen to its lowest point in the entire recorded period, bottoming out at approximately 3.0.\n"
      ],
      "metadata": {
        "id": "p3Rek8FhaKWt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Feature Engineering: Creating the Sentiment Column\n",
        "\n",
        "Having completed our exploratory analysis, we now resume data preparation for the model. The critical next step is to convert the numerical `rating` into categorical `sentiment` labels. This process creates the target variable for our classification model.\n",
        "\n",
        "We will apply the following logical mapping:\n",
        "* **Ratings 1-4**: Classified as **Negative**.\n",
        "* **Ratings 5-6**: Classified as **Neutral**.\n",
        "* **Ratings 7-10**: Classified as **Positive**.\n",
        "\n",
        "This grouping is a standard practice that effectively segments the reviews into the distinct classes our model will learn to predict. After creating this new column, we will immediately visualize its distribution."
      ],
      "metadata": {
        "id": "0EG_kXGRajR0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to map ratings to sentiment categories\n",
        "def to_sentiment(rating):\n",
        "    \"\"\"Converts a numerical rating into a sentiment category.\"\"\"\n",
        "    if rating <= 4:\n",
        "        return 'Negative'\n",
        "    elif rating <= 6:\n",
        "        return 'Neutral'\n",
        "    else:  # Ratings 7, 8, 9, 10\n",
        "        return 'Positive'\n",
        "\n",
        "# Apply the function to the 'rating' column in our final DataFrame\n",
        "df_final['sentiment'] = df_final['rating'].apply(to_sentiment)\n",
        "\n",
        "print(\"Successfully created the 'sentiment' column.\")\n",
        "print(\"\\nVerifying the mapping for the first 10 rows:\")\n",
        "display(df_final[['rating', 'sentiment']].head(10))"
      ],
      "metadata": {
        "id": "mHZAYIfSY_ZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Visualizing Sentiment Distribution\n",
        "\n",
        "With the `sentiment` column now engineered, the final step of our EDA is to visualize the distribution of these sentiment categories. A count plot will provide a clear, quantitative view of the class balance in our dataset.\n",
        "\n",
        "This is a mandatory checkpoint before proceeding to model training. It allows us to:\n",
        "1.  Confirm the extent of the class imbalance that was suggested by the initial rating distribution.\n",
        "2.  Understand the final number of samples available for each category ('Negative', 'Neutral', 'Positive').\n",
        "\n",
        "This visualization provides the definitive class distribution that our machine learning model will be trained on."
      ],
      "metadata": {
        "id": "qw71EyjXa0eT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a custom color palette for sentiment categories\n",
        "# Ensuring distinct, brighter, and intuitive colors\n",
        "sentiment_colors = {\n",
        "    'Negative': '#FF6347',  # Tomato Red\n",
        "    'Neutral': '#ADD8E6',   # Light Blue\n",
        "    'Positive': '#3CB371'   # Medium Sea Green\n",
        "}\n",
        "\n",
        "# Set the figure size for the plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "# Create a count plot for the 'sentiment' column with the custom palette\n",
        "sns.countplot(x='sentiment',\n",
        "              data=df_final,\n",
        "              order=['Negative', 'Neutral', 'Positive'],\n",
        "              palette=sentiment_colors) # Use the custom palette here\n",
        "\n",
        "# Add a clear title and labels\n",
        "plt.title('Final Distribution of Sentiment Categories', fontsize=16)\n",
        "plt.xlabel('Sentiment', fontsize=12)\n",
        "plt.ylabel('Number of Reviews', fontsize=12)\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wvZT0K1Xan4N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2: Model Preparation and Tokenization\n",
        "\n"
      ],
      "metadata": {
        "id": "_Z3wnDScbcGI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the necessary libraries from Hugging Face\n",
        "!pip install transformers datasets -q\n",
        "\n",
        "# Import the specific components we will need\n",
        "from datasets import Dataset\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "\n",
        "print(\"Hugging Face libraries installed and imported successfully.\")"
      ],
      "metadata": {
        "id": "qgV9_tDMa5qJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Model Data Preparation\n",
        "\n",
        "To prepare the data, we will perform three key steps:\n",
        "\n",
        "1.  **Map Labels to Integers**: Convert sentiment labels ('Negative', etc.) to a numerical format (0, 1, 2).\n",
        "2.  **Stratified Split**: Divide the data into training and testing sets, ensuring the same sentiment proportions in both to handle our class imbalance.\n",
        "3.  **Tokenization**: Use a DistilBERT tokenizer to convert review text into the numerical IDs and attention masks required by the model."
      ],
      "metadata": {
        "id": "14Jwlaj4cO-Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 1. Map text labels to integers\n",
        "label_map = {'Negative': 0, 'Neutral': 1, 'Positive': 2}\n",
        "df_final['label'] = df_final['sentiment'].map(label_map)\n",
        "\n",
        "# 2. Split the DataFrame into training and testing sets (80/20 split)\n",
        "# We stratify by 'sentiment' to maintain class distribution in both sets\n",
        "train_df, test_df = train_test_split(\n",
        "    df_final,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=df_final['sentiment']\n",
        ")\n",
        "\n",
        "# 3. Load the DistilBERT tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "\n",
        "# 4. Convert pandas DataFrames to Hugging Face Dataset objects\n",
        "train_dataset = Dataset.from_pandas(train_df)\n",
        "test_dataset = Dataset.from_pandas(test_df)\n",
        "\n",
        "# 5. Define a function to tokenize the 'review' text\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"review\"], padding=\"max_length\", truncation=True)\n",
        "\n",
        "# 6. Apply the tokenizer to the entire datasets\n",
        "tokenized_train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "tokenized_test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "print(\"Data successfully split and tokenized.\")\n",
        "print(f\"Training set size: {len(tokenized_train_dataset)}\")\n",
        "print(f\"Testing set size: {len(tokenized_test_dataset)}\")"
      ],
      "metadata": {
        "id": "ZEn4bfuxblvR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Model and Trainer Configuration\n"
      ],
      "metadata": {
        "id": "MYXPwL0mdTK2"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5390c87"
      },
      "source": [
        "## 11. Model Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Initialize the TF-IDF Vectorizer\n",
        "# We'll limit it to the top 5000 most frequent words to keep it efficient.\n",
        "tfidf = TfidfVectorizer(max_features=5000, stop_words='english')\n",
        "\n",
        "# Fit the vectorizer on the TRAINING data and transform it\n",
        "X_train = tfidf.fit_transform(train_df['review'])\n",
        "\n",
        "# ONLY transform the TESTING data using the already-fitted vectorizer\n",
        "X_test = tfidf.transform(test_df['review'])\n",
        "\n",
        "# Get the labels\n",
        "y_train = train_df['label']\n",
        "y_test = test_df['label']\n",
        "\n",
        "print(f\"✅ TF-IDF vectors created.\")\n",
        "print(f\"Training data shape: {X_train.shape}\")\n",
        "print(f\"Testing data shape: {X_test.shape}\")"
      ],
      "metadata": {
        "id": "Eg_nNGwMd6yt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Initialize the model with the crucial class_weight parameter\n",
        "model = LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(\"✅ Logistic Regression model trained successfully.\")"
      ],
      "metadata": {
        "id": "FwuH7XjlhIft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Generate and print the classification report\n",
        "report = classification_report(y_test, y_pred, target_names=['Negative', 'Neutral', 'Positive'])\n",
        "\n",
        "print(\"--- Final Model Performance ---\")\n",
        "print(report)"
      ],
      "metadata": {
        "id": "UfaY_SMSrMTq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Re-initialize the TF-IDF Vectorizer with n-grams\n",
        "tfidf_ngram = TfidfVectorizer(\n",
        "    max_features=5000,\n",
        "    stop_words='english',\n",
        "    ngram_range=(1, 2)  # This tells it to use both single words and pairs of words\n",
        ")\n",
        "\n",
        "# Re-create the feature matrices\n",
        "X_train_ngram = tfidf_ngram.fit_transform(train_df['review'])\n",
        "X_test_ngram = tfidf_ngram.transform(test_df['review'])\n",
        "\n",
        "# Train a new model on these improved features\n",
        "model_ngram = LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42)\n",
        "model_ngram.fit(X_train_ngram, y_train)\n",
        "\n",
        "# Evaluate the new model\n",
        "y_pred_ngram = model_ngram.predict(X_test_ngram)\n",
        "report_ngram = classification_report(y_test, y_pred_ngram, target_names=['Negative', 'Neutral', 'Positive'])\n",
        "\n",
        "print(\"--- Performance with N-grams ---\")\n",
        "print(report_ngram)"
      ],
      "metadata": {
        "id": "suNhaZBgrOld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the counts for each category in the entire dataset\n",
        "print(df_final['sentiment'].value_counts())"
      ],
      "metadata": {
        "id": "Zo05TwzSr1nU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Define the new mapping function\n",
        "def to_sentiment_new(rating):\n",
        "    if rating <= 3:\n",
        "        return 'Negative'\n",
        "    elif rating <= 7:\n",
        "        return 'Neutral'\n",
        "    else: # Ratings 8, 9, 10\n",
        "        return 'Positive'\n",
        "\n",
        "# 2. Apply the new mapping to our original DataFrame\n",
        "df_new_labels = df_final.copy()\n",
        "df_new_labels['sentiment'] = df_new_labels['rating'].apply(to_sentiment_new)\n",
        "df_new_labels['label'] = df_new_labels['sentiment'].map({'Negative': 0, 'Neutral': 1, 'Positive': 2})\n",
        "\n",
        "# Let's see the new distribution\n",
        "print(\"--- New Sentiment Distribution ---\")\n",
        "print(df_new_labels['sentiment'].value_counts())\n",
        "\n",
        "# 3. Perform a new train-test split with the new labels\n",
        "train_df_new, test_df_new = train_test_split(\n",
        "    df_new_labels,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=df_new_labels['sentiment']\n",
        ")\n",
        "\n",
        "# 4. Re-run the TF-IDF and LinearSVC model\n",
        "# (This uses the same code as before, just with the new data)\n",
        "tfidf_ngram = TfidfVectorizer(max_features=5000, stop_words='english', ngram_range=(1, 2))\n",
        "X_train_new = tfidf_ngram.fit_transform(train_df_new['review'])\n",
        "X_test_new = tfidf_ngram.transform(test_df_new['review'])\n",
        "y_train_new = train_df_new['label']\n",
        "y_test_new = test_df_new['label']\n",
        "\n",
        "model_svc_new = LinearSVC(class_weight='balanced', max_iter=2000, random_state=42)\n",
        "model_svc_new.fit(X_train_new, y_train_new)\n",
        "\n",
        "y_pred_svc_new = model_svc_new.predict(X_test_new)\n",
        "report_svc_new = classification_report(y_test_new, y_pred_svc_new, target_names=['Negative', 'Neutral', 'Positive'])\n",
        "\n",
        "print(\"\\n--- Performance with New Labels ---\")\n",
        "print(report_svc_new)"
      ],
      "metadata": {
        "id": "hUQqSe5vs0_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. Create a binary dataset (Positive vs. Negative)\n",
        "df_binary = df_final[df_final['sentiment'] != 'Neutral'].copy()\n",
        "df_binary['label'] = df_binary['sentiment'].map({'Negative': 0, 'Positive': 1})\n",
        "\n",
        "print(\"--- Binary Data Distribution ---\")\n",
        "print(df_binary['sentiment'].value_counts())\n",
        "\n",
        "# 2. Perform a new train-test split on the binary data\n",
        "train_df_bin, test_df_bin = train_test_split(\n",
        "    df_binary,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=df_binary['sentiment']\n",
        ")\n",
        "\n",
        "# 3. Create TF-IDF features with N-grams\n",
        "tfidf_ngram = TfidfVectorizer(max_features=5000, stop_words='english', ngram_range=(1, 2))\n",
        "X_train_bin = tfidf_ngram.fit_transform(train_df_bin['review'])\n",
        "X_test_bin = tfidf_ngram.transform(test_df_bin['review'])\n",
        "y_train_bin = train_df_bin['label']\n",
        "y_test_bin = test_df_bin['label']\n",
        "\n",
        "# 4. Train the final LinearSVC model\n",
        "# Note: We don't need class_weight='balanced' anymore as the classes are now much more balanced.\n",
        "final_model = LinearSVC(max_iter=2000, random_state=42)\n",
        "final_model.fit(X_train_bin, y_train_bin)\n",
        "\n",
        "# 5. Evaluate the final model\n",
        "y_pred_bin = final_model.predict(X_test_bin)\n",
        "final_report = classification_report(y_test_bin, y_pred_bin, target_names=['Negative', 'Positive'])\n",
        "\n",
        "print(\"\\n--- Final Binary Model Performance ---\")\n",
        "print(final_report)\n",
        "\n",
        "# 6. Visualize the results with a confusion matrix\n",
        "print(\"\\n--- Confusion Matrix ---\")\n",
        "ConfusionMatrixDisplay.from_predictions(y_test_bin, y_pred_bin, display_labels=['Negative', 'Positive'], cmap='Blues')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5Uc1jBa_ttAG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# 1. Define the parameter grid to search\n",
        "# These values are common choices for the 'C' parameter\n",
        "param_grid = {'C': [0.1, 1, 10, 100]}\n",
        "\n",
        "# 2. Initialize GridSearchCV\n",
        "# It will test each 'C' value using 5-fold cross-validation\n",
        "grid_search = GridSearchCV(\n",
        "    LinearSVC(max_iter=2000, random_state=42),\n",
        "    param_grid,\n",
        "    cv=5,\n",
        "    scoring='f1_weighted', # We'll optimize for the best F1-score\n",
        "    n_jobs=-1 # Use all available CPU cores\n",
        ")\n",
        "\n",
        "# 3. Run the search on the training data\n",
        "grid_search.fit(X_train_bin, y_train_bin)\n",
        "\n",
        "print(f\"✅ Best C value found: {grid_search.best_params_['C']}\")\n",
        "\n",
        "# 4. Evaluate the best model found by the grid search on the test set\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred_best = best_model.predict(X_test_bin)\n",
        "report_best = classification_report(y_test_bin, y_pred_best, target_names=['Negative', 'Positive'])\n",
        "\n",
        "print(\"\\n--- Performance with Tuned Hyperparameters ---\")\n",
        "print(report_best)"
      ],
      "metadata": {
        "id": "X-lVLc2WuevS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Re-initialize TF-IDF with optimized parameters\n",
        "tfidf_optimized = TfidfVectorizer(\n",
        "    max_features=5000,\n",
        "    stop_words='english',\n",
        "    ngram_range=(1, 2),\n",
        "    min_df=5,       # Word must appear in at least 5 reviews\n",
        "    max_df=0.9      # Word must appear in no more than 90% of reviews\n",
        ")\n",
        "\n",
        "# 2. Re-create the feature matrices\n",
        "X_train_opt = tfidf_optimized.fit_transform(train_df_bin['review'])\n",
        "X_test_opt = tfidf_optimized.transform(test_df_bin['review'])\n",
        "\n",
        "# 3. Train the final, fully-tuned model\n",
        "# Use the best 'C' value we found from GridSearchCV above\n",
        "best_c_value = grid_search.best_params_['C']\n",
        "final_tuned_model = LinearSVC(C=best_c_value, max_iter=2000, random_state=42)\n",
        "final_tuned_model.fit(X_train_opt, y_train_bin)\n",
        "\n",
        "# 4. Evaluate the fully tuned model\n",
        "y_pred_final = final_tuned_model.predict(X_test_opt)\n",
        "report_final = classification_report(y_test_bin, y_pred_final, target_names=['Negative', 'Positive'])\n",
        "\n",
        "print(\"\\n--- Performance with Tuned Hyperparameters and Features ---\")\n",
        "print(report_final)"
      ],
      "metadata": {
        "id": "ZxQfkVszv8fz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Re47xsawv_2t"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}